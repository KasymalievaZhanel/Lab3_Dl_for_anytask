{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KasymalievaZhanel/Lab3_Dl_for_anytask/blob/main/Lab2_DL_part3_poetry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNa9FRE3FErB"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpgEw1dFErL"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RCr6MixFErO"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkxG_AyvFErQ"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFSXpH60FErQ"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnzxWrPrRk61"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSAeda4ZFErS"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpAVwvsyRJhW",
        "outputId": "dc72774e-c2f8-45ab-f9ae-6cd05a8006e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['  From fairest creatures we desire increase,\\n', \"  That thereby beauty's rose might never die,\\n\", '  But as the riper should by time decease,\\n', '  His tender heir might bear his memory:\\n', '  But thou, contracted to thine own bright eyes,\\n', \"  Feed'st thy light's flame with self-substantial fuel,\\n\", '  Making a famine where abundance lies,\\n', '  Thy self thy foe, to thy sweet self too cruel:\\n', \"  Thou that art now the world's fresh ornament,\\n\", '  And only herald to the gaudy spring,\\n']\n"
          ]
        }
      ],
      "source": [
        "print(text[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x59qxi8OFErT",
        "outputId": "b9912947-0e76-49bb-9985-2fbbca0d865e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK!\n"
          ]
        }
      ],
      "source": [
        "text = ''.join(text).lower()\n",
        "\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lutf6WH5FErZ"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62cnrKqHFEra",
        "outputId": "8ff436ce-796b-43e5-9b47-33f08e91d08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ],
      "source": [
        "tokens = sorted(set(text))\n",
        "num_tokens = len(tokens)\n",
        "print(num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAuwqzXwFErb"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sTuHp_kvFErc"
      },
      "outputs": [],
      "source": [
        "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
        "idx_to_token = {idx: token for idx, token in enumerate(tokens)}\n",
        "assert len(token_to_idx) == len(idx_to_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIlC5fwcFErd"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYFdpdjyFEre"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lfOEUziFErf"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0BJFa6zmFErf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "plt.style.use('ggplot')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thW-tw_NgvyO"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 120\n",
        "BATCH_SIZE = 200\n",
        "NUM_BATCHES = (len(text) - MAX_LEN) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwEjuLUdTCaO"
      },
      "outputs": [],
      "source": [
        "def to_matrix(pieces, max_len=None):\n",
        "  if max_len == None: \n",
        "    max_len = max(map(len, pieces))\n",
        "\n",
        "  text_ix = np.zeros((len(pieces), max_len), dtype='int32')\n",
        "  for i in range(len(pieces)): \n",
        "    line_ix = [token_to_idx[c] for c in pieces[i]]\n",
        "    text_ix[i, :len(line_ix)] = line_ix\n",
        "  return text_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bRjDGIZT3kK"
      },
      "outputs": [],
      "source": [
        "class CharRNNCell(nn.Module):\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
        "        \n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        x_emb = self.embedding(x)\n",
        "        \n",
        "        # compute next hidden state using self.rnn_update\n",
        "        # hint: use torch.cat(..., dim=...) for concatenation\n",
        "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
        "        h_next = self.rnn_update(x_and_h)\n",
        "        h_next = torch.tanh(h_next)\n",
        "        assert h_next.size() == h_prev.size()\n",
        "        \n",
        "        #compute logits for next character probs\n",
        "        logits = self.rnn_to_logits(h_next)\n",
        "        \n",
        "        return h_next, F.log_softmax(logits, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units, requires_grad=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGe8o0_EVQpU"
      },
      "outputs": [],
      "source": [
        "def RNNLoop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in names_ix\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "    logprobs = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0,1):\n",
        "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
        "        logprobs.append(logp_next)\n",
        "        \n",
        "    return torch.stack(logprobs, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkGzkMZOVmkY"
      },
      "outputs": [],
      "source": [
        "def get_next_str(num, start=0, piece_len=100, step=1):\n",
        "  res = []\n",
        "  for i in range(num): \n",
        "    if start + piece_len >= len(text) - 1:\n",
        "      print(\"FFFFFF\")\n",
        "      break\n",
        "    else :\n",
        "      end = start + piece_len \n",
        "      res.append(text[start:end])\n",
        "      start += step\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "tqdm._instances.clear()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "H_iURDxI9wMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(opt, rnn) :\n",
        "  current_epoch_loss = 0\n",
        "  for batch_idx in trange(NUM_BATCHES):\n",
        "    matr_str = to_matrix(get_next_str(BATCH_SIZE, start=batch_idx * BATCH_SIZE, piece_len=MAX_LEN))\n",
        "    samples = torch.tensor(matr_str, dtype=torch.int64).to(device)\n",
        "    batch_ix = samples[:, :-1]\n",
        "\n",
        "    opt.zero_grad()\n",
        "    logp_seq = RNNLoop(rnn, batch_ix)\n",
        "    predictions_logp = logp_seq\n",
        "\n",
        "    actual_next_tokens = samples[:, 1:]\n",
        "    logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "    loss = -logp_next.mean()\n",
        "    \n",
        "    current_epoch_loss += loss.detach().cpu().numpy()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  return current_epoch_loss  "
      ],
      "metadata": {
        "id": "0Q0iDB0SV4xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_report(current_epoch_loss, epoch, loss_history) :\n",
        "    print('Training epoch: {} Loss: {}'.format(epoch, current_epoch_loss))\n",
        "    clear_output(True)\n",
        "    plt.plot(loss_history,label='loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pj98KF-TbaBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP6veHQyVfDd"
      },
      "outputs": [],
      "source": [
        "def training_loop(rnn, opt, epochs):\n",
        "  loss_history = []\n",
        "  for epoch in range(epochs):\n",
        "    current_epoch_loss = train_epoch(opt, rnn)\n",
        "    current_epoch_loss /= NUM_BATCHES\n",
        "    loss_history.append(current_epoch_loss)\n",
        "    print_report(current_epoch_loss, epoch, loss_history)\n",
        "  return loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KAGGfunQWYrM",
        "outputId": "9f4cda72-0c07-42c4-c9f1-8069060531a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "char_rnn = CharRNNCell().to(device)\n",
        "opt = torch.optim.Adam(char_rnn.parameters())\n",
        "loss_history = training_loop(char_rnn, opt, 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_7R1wvXIFErg"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCcS53GoFErh"
      },
      "outputs": [],
      "source": [
        "def generate_sample(char_rnn, seed_phrase='hello', max_length=MAX_LEN, temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
        "        smaller temperature converges to the single most likely output.\n",
        "        \n",
        "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
        "    of the next symbol.\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "  \n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        # print(x_sequence[:, -1].shape, hid_state.shape)\n",
        "        hid_state, out = char_rnn(x_sequence[:, i], hid_state)\n",
        "  \n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, out = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        # Be really careful here with the model output\n",
        "        p_next = F.softmax(out / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.cpu().numpy()[0]])   \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OevJQfXFErh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51cd7be1-5e0f-4dc2-9fa0-4e5b7c62861d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my friend will forgernce to desself i will thou evind thee is my love, and fairs;\n",
            "  though that i eye so my for thou sare to so that touchen this show hours they love love is plaves thy self be for even to mine and thou that exce pornes conthify,\n",
            "  abp'd thee my comple was thy all thou thy art not vilve more sour in thee fecellact, was spert i to thy lov'd part\n",
            "  with from my dear,\n",
            "  if both not of thinks eyes,\n",
            "  who mast is that i say my mence fair:\n",
            "  thy mely due to hate the fick thou breason \n"
          ]
        }
      ],
      "source": [
        "# An example of generated text.\n",
        "print(generate_sample(char_rnn, seed_phrase='my friend', max_length=500, temperature=0.8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTWGN6h8FEri"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL9vl6ufFEri"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EUfrpHj3FEri"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.LSTMCell(embedding_size, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        x_emb = self.embedding(x)\n",
        "        \n",
        "        # compute next hidden state using self.rnn_update\n",
        "        # hint: use torch.cat(..., dim=...) for concatenation\n",
        "        h_next = self.rnn_update(x_emb, h_prev)\n",
        "        \n",
        "        #compute logits for next character probs\n",
        "        logits = self.rnn_to_logits(h_next[0])\n",
        "        return h_next, F.log_softmax(logits, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return [torch.zeros(batch_size, self.num_units, requires_grad=True).to(device) for i in range(2)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_rnn = LSTMCell().to(device)\n",
        "lstm_opt = torch.optim.Adam(lstm_rnn.parameters())"
      ],
      "metadata": {
        "id": "daPl7ls9tSzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history_lstm = training_loop(lstm_rnn, lstm_opt, 35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "kDutAg-UtV6h",
        "outputId": "5d5f771b-e88f-4bed-db0e-4ebd15c8ba48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(lstm_rnn, seed_phrase='my friend', max_length=500, temperature=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g66TsWVttZk5",
        "outputId": "b1f7dea7-b641-4518-a061-9947118cfe0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my friends seal to,.\n",
            "  xxciii\n",
            "\n",
            "  whowh, which by they, not better and dote.\n",
            "  o! her care strand lov'st chund to praise,\n",
            "  long it what lies to thy hold can eyes precont\n",
            "  many do ellled doth true,\n",
            "  cundlatil'd upon a leal;\n",
            "  to mysearion and bortlays past,\n",
            "  that nighning tan eye more doth with this dear so;\n",
            "  my arouthacoud thee hate;\n",
            "  with thine uy. prove i save thom fan one breavtil with mine\n",
            "  rity are his wrild a courr'd;\n",
            "  sifift to sungety dewards thinemed to me,\n",
            "  o! 'will-thy love i \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REORFSUyFErj"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ry2twNEmFErj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c2403a-dce0-4178-a35e-0194fa9a839a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***\n",
            "\n",
            "my friend the state,\n",
            "  the store the world the state the state the state,\n",
            "  that i as the store the state that the state,\n",
            "  that i the strand the state the state the state the state\n",
            "  the world the world thou thou art the world the state,\n",
            "  and the state the store the state the state the state,\n",
            "  and thou thou thou thou thou thou thou art the state,\n",
            "  that i have the state the state the state the state,\n",
            "  and the state the world the state the state the state,\n",
            "  the world the world that the world\n",
            "\n",
            "***\n",
            "\n",
            "my friend and thou thee,\n",
            "  which i have the world and the world thou art the constance thee strength\n",
            "  and the may the true the state, and the store i fair to thee all thee thee strength thee shown,\n",
            "  that the world the true the world the sweet doth steel to me still dear thee thee,\n",
            "  and the world thou thou thou thee strainst the store i have the world to me strange,\n",
            "  the hath thy so thy stranguly my hath thee be doth thee strange,\n",
            "  and the world that i all thee the state in the state,\n",
            "  and \n",
            "\n",
            "***\n",
            "\n",
            "my friend of my that thy state;\n",
            "  that thy heart ending thou with my fair, though my farther, that store eyes,\n",
            "  when do by thy made i fair a can me me i have sterest my self is or,\n",
            "  who his from i an appace the mayst that is a part,\n",
            "  and the world not me not thee i his will be dear what i have thee stay\n",
            "  and me thou art state the hand for the give thy seeds,\n",
            "  so me thou love i an very so that thou they this grown thine.\n",
            "\n",
            "  cxxxvi\n",
            "\n",
            "  when see in thy love thou reads to seemen of the sweet,\n",
            "  \n",
            "\n",
            "***\n",
            "\n",
            "my friends hor-ther, excros sweet doth saised,\n",
            "  ltant to take, not sweets of tempow;\n",
            "    loving with kine!--ry, bestle vays:\n",
            "    do hought that a chell me for the bath hald!\n",
            "  that blass arpeetin\n",
            "  thu happy the baspains i assuent keep i folse me steep doth in my chased disw;\n",
            "  if poserfillle setceash agnother far not.\n",
            "    absears'd thy thought fob to thee upohe heart;\n",
            "  and throws, o! why ball in thy preisl'd whil paint\n",
            "  a coverit them held which in thy hist other dead.\n",
            "\n",
            "  cxlii\n",
            "\n",
            "  for they d\n",
            "\n",
            "***\n",
            "\n",
            "my friend incy's,: \n",
            "e hoinothorg'd,, that noter?\n",
            " n okrcemulacted, fep thy woved ply!\n",
            "\n",
            "  cxxii.\n",
            "\n",
            "  bothing sap ivu'ht, fcol hy je well; vouck f, alevy youm the gragt,\n",
            "  myy-rif-dete, in aru beds-dear't\n",
            " yxcravesz ghand! bedovs, loosted liflithmp-e;.\n",
            "  sapceould, inoly maybject stilded kinwn'\n",
            ";\n",
            "  miffuny quet,-laqueim own pomb: ot.\n",
            "\n",
            "  xc'\n",
            "\n",
            "  galy div'dsite do broamporrfarmy hobd:\n",
            "  memurckal,--\n",
            "  his minuge thus'd?\n",
            "  mnis jactoud apay; creevise, alt lov's-wfettefayst; i smage'on my?-sishnce life\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='my friend', max_length=500, temperature=0.1))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='my friend', max_length=500, temperature=0.2))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='my friend', max_length=500, temperature=0.5))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='my friend', max_length=500, temperature=1))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='my friend', max_length=500, temperature=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that on low temperature (like 0.1) the net often repeats the same words (probably the most frequent) so the generated text mostly consists of \"thee\" and \"the world\". Not much fun, actually.\n",
        "\n",
        "On 0.2 the situation is pretty similar, but there are more different words appearing, lines are usually shorter (that's good).\n",
        "\n",
        "0.5 is nice, no weird repetitions and most of the words are real. It still does not make any sense, but that's not what we're here for.\n",
        "\n",
        "1.0 is my fav here! Beautiful structure, lots of punctuation, some grammatically correct pieces can be found.\n",
        "\n",
        "On 2.0 the net goes crazy and just messes everything up. No meaningful or at least readable words, punctuation everywhere."
      ],
      "metadata": {
        "id": "eQcKD8WGtuIz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI9PGUlUFErk"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R00cTPUFErk"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FaP4MBx5FErk"
      },
      "outputs": [],
      "source": [
        "torch.save(lstm_rnn, 'model')\n",
        "loaded = torch.load('model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(loaded, seed_phrase='my friend', max_length=500, temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "den2KJXUt0NI",
        "outputId": "ad0df8fc-3580-4eda-ea2a-233808780bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my friend are for me now falled for this so aft to,\n",
            "  yet guph that sweet mestants, now pern,\n",
            "  and eyes and to praise i will his pread,\n",
            "  since do yours of hasting seem thy love thou lie show,\n",
            "    that desiry and in thine eye, and beauty's me thou,\n",
            "  by love this to day, and i do infect stard,\n",
            "    her thou thou me am the slander thy proves not from in these can delad to thou me.\n",
            "\n",
            "  clii\n",
            "\n",
            "  who mistere both self spees that that should desperal fangel am of eye,\n",
            "  back for no were finding doth be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIn5pSa2FErl"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "name": "Lab2_DL_part3_poetry.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}